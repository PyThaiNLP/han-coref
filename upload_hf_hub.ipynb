{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb7890f-1792-4e26-b169-88f76e3c8a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb505fef-2dac-4226-87ff-5d96fbb15595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path,\"r\",encoding=\"utf-8-sig\") as f:\n",
    "        _data = [eval(i) for i in f.readlines()]\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90cc9dda-099b-4122-85b2-3925882fd739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=read_file(\"dataset/train_2152023_newmm.jsonlines\")\n",
    "val_data=read_file(\"dataset/val_2152023_newmm.jsonlines\")\n",
    "test_data=read_file(\"dataset/test_2152023_newmm.jsonlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30aead80-90be-4d2c-8cac-2efaeb3bffb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'ศรี จันทน รองประธานสหพันธ์มวยกัมพูชา ออกมาโพสต์ผ่านเฟซบุ๊กของตัวเอง หลังจากที่ เซียน เลวี นักชกกุน แขมร์ ขวัญใจเจ้าถิ่น พ่ายน็อกยก 4 ให้กับ แซมมี่ บัญชาเมฆ นักชกไทย ในการแข่งขันกุน แขมร์ ที่เสียมราฐ ประเทศกัมพูชา เมื่อวันที่ 15 เมษายนที่ผ่านมา',\n",
       " 'clusters': [[[0, 9], [61, 67]]],\n",
       " 'clusters_strings': [['ศรี จันทน', 'ตัวเอง']],\n",
       " 'source': 'Thai sport news from matichon.co.th (Sport news)'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64103be-cc75-4785-b063-f77497b1ab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d={\n",
    "    \"train\":{\n",
    "        \"text\":[i[\"text\"] for i in train_data],\n",
    "        \"clusters\":[i[\"clusters\"] for i in train_data],\n",
    "        \"clusters_strings\":[i[\"clusters_strings\"] for i in train_data],\n",
    "        \"source\":[i[\"source\"] for i in train_data],\n",
    "    },\n",
    "    \"test\":{\n",
    "        \"text\":[i[\"text\"] for i in test_data],\n",
    "        \"clusters\":[i[\"clusters\"] for i in test_data],\n",
    "        \"clusters_strings\":[i[\"clusters_strings\"] for i in test_data],\n",
    "        \"source\":[i[\"source\"] for i in test_data],\n",
    "    },\n",
    "    \"validation\":{\n",
    "        \"text\":[i[\"text\"] for i in val_data],\n",
    "        \"clusters\":[i[\"clusters\"] for i in val_data],\n",
    "        \"clusters_strings\":[i[\"clusters_strings\"] for i in val_data],\n",
    "        \"source\":[i[\"source\"] for i in val_data],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1bddb1-0153-4cb4-825c-809fe31d4963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = datasets.DatasetDict()\n",
    "# using your `Dict` object\n",
    "for k,v in d.items():\n",
    "    dataset[k] = Dataset.from_dict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32199100-9ca1-473b-adb9-7a562cc67782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'clusters', 'clusters_strings', 'source'],\n",
       "        num_rows: 1039\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'clusters', 'clusters_strings', 'source'],\n",
       "        num_rows: 149\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'clusters', 'clusters_strings', 'source'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06ab435-aabf-4328-81d4-2ae6624557c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624825d668ad421e92ade895a3dbabac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f84a8ba959e4c3aa6166ae1d9852d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5209acc0a7344b93aba6c2f32f23c4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3291560dc715430c8e16085b1d9b3067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b89163512804655b52ecca621c881e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66176798926844f489c32b22fb8044f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c92499b0fe24d95b62104e37f7a1dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3d205cf5914b26b57e4e319797c154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e93006ff054ceabd0222b567ba2b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"pythainlp/han-corf-dataset-v1.0\",private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07921803-dfd0-4e92-be08-592c4a9b9b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
